{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sounds are distinct and instantly recognizable, like a baby’s laugh or the strum of a guitar.\n",
    "\n",
    "Other sounds aren’t clear and are difficult to pinpoint. If you close your eyes, can you tell which of the sounds below is a chainsaw versus a blender?\n",
    "\n",
    "Moreover, we often experience a mix of sounds that create an ambience – like the clamoring of construction, a hum of traffic from outside the door, blended with loud laughter from the room, and the ticking of the clock on your wall. The sound clip below is of a busy food court in the UK.\n",
    "\n",
    "Partly because of the vastness of sounds we experience, no reliable automatic general-purpose audio tagging systems exist. Currently, a lot of manual effort is required for tasks like annotating sound collections and providing captions for non-speech events in audiovisual content.\n",
    "\n",
    "To tackle this problem, Freesound (an initiative by MTG-UPF that maintains a collaborative database with over 370,000 Creative Commons Licensed sounds) and Google Research’s Machine Perception Team (creators of AudioSet, a large-scale dataset of manually annotated audio events with over 500 classes) have teamed up to develop the dataset for this competition.\n",
    "\n",
    "You’re challenged to build a general-purpose automatic audio tagging system using a dataset of audio files covering a wide range of real-world environments. Sounds in the dataset include things like musical instruments, human sounds, domestic sounds, and animals from Freesound’s library, annotated using a vocabulary of more than 40 labels from Google’s AudioSet ontology. To succeed in this competition your systems will need to be able to recognize an increased number of sound events of very diverse nature, and to leverage subsets of training data featuring annotations of varying reliability (see Data section for more information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../src')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nono/miniconda3/envs/librosa/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning:\n",
      "\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from information import Information\n",
    "from pre_processing import PreProcessing\n",
    "from prepare_data import PrepareData\n",
    "from sound_oop import SoundObjectOriented\n",
    "from utils.sound_features import get_mfcc_features_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load environment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load envs\n",
    "\n",
    "ENV = os.getenv(\"ENV\")\n",
    "TRAIN_PATH = os.getenv(\"TRAIN_PATH\")\n",
    "TEST_PATH = os.getenv(\"TRAIN_PATH\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test_post_competition.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = list(train.label.unique())\n",
    "label_idx = {label: i for i, label in enumerate(LABELS)}\n",
    "train.set_index(\"fname\", inplace=True)\n",
    "test.set_index(\"fname\", inplace=True)\n",
    "train[\"label_idx\"] = train.label.apply(lambda x: label_idx[x])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract MFCC for noth train/test audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pre-processing object is created\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:04<00:00,  7.68it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00,  9.83it/s]\n"
     ]
    }
   ],
   "source": [
    "prepare_data = PrepareData()\n",
    "train_extracted = prepare_data.extract_features(\n",
    "    \"../data/train\", \"train\", loadPreComputed=False\n",
    ")\n",
    "test_extracted = prepare_data.extract_features(\n",
    "    \"../data/test\", \"test\", loadPreComputed=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract cooresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc[train_extracted.index.to_numpy()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the main Sound Classifier Object and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Information object is created\n",
      "\n",
      "\n",
      "pre-processing object is created\n",
      "\n",
      "\n",
      "SoundObjectOriented object is created\n",
      "\n",
      "\n",
      "Your data has been added\n",
      "\n",
      "\n",
      "Data has been Pre-Processed\n",
      "\n",
      "\n",
      "Machine Learning object is created\n",
      "\n",
      "==================================================\n",
      "You can fit your data with the following models\n",
      "================================================== \n",
      "\n",
      "Elastic Net\n",
      "Kernel Ridge\n",
      "Bayesian Ridge\n",
      "Lasso\n",
      "Lasso Lars Ic\n",
      "Random Forest\n",
      "Svm\n",
      "Xgboost\n",
      "Gradient Boosting\n",
      "\n",
      " ================================================== \n",
      "\n",
      "Elastic Net ========= > Initialized\n",
      "Kernel Ridge ======== > Initialized\n",
      "Bayesian Ridge ====== > Initialized\n",
      "Lasso =============== > Initialized\n",
      "Lasso Lars Ic ======= > Initialized\n",
      "Random Forest ======= > Initialized\n",
      "Svm ================= > Initialized\n",
      "Xgboost ============= > Initialized\n",
      "Gradient Boosting === > Initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nono/miniconda3/envs/librosa/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.040e-01, tolerance: 8.210e-02\n",
      "\n",
      "/home/nono/miniconda3/envs/librosa/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e-02, tolerance: 5.833e-04\n",
      "\n",
      "/home/nono/miniconda3/envs/librosa/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n",
      "\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.393e+00, tolerance: 3.821e-01\n",
      "\n",
      "/home/nono/miniconda3/envs/librosa/lib/python3.10/site-packages/sklearn/linear_model/_base.py:148: FutureWarning:\n",
      "\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ========================= Elastic Net =========================\n",
      "********** Training *********************** Testing **********\n",
      "R^2    :  0.9999970849106857         -1.185583323982778\n",
      "Adj R^2:  1.0000000156032243         1.0116984911453581\n",
      "MAE    :  0.0008913791841930812      86.30391357910844\n",
      "MSE    :  2.360883663676816e-06      86.30391357910844\n",
      "RMSE   :  0.0015365167306856168      9.289989966577382\n",
      "\n",
      " ========================= Kernel Ridge =========================\n",
      "********** Training *********************** Testing **********\n",
      "R^2    :  0.9999999999997233         -2.247238345432569\n",
      "Adj R^2:  1.0000000000000016         1.017381075621352\n",
      "MAE    :  1.0646782014036817e-06     106.86810486295758\n",
      "MSE    :  2.5660898943927996e-11     106.86810486295758\n",
      "RMSE   :  5.065658786764856e-06      10.337703074811037\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (24, 3) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m ML\u001b[39m.\u001b[39mshow_available_algorithms()\n\u001b[1;32m      9\u001b[0m ML\u001b[39m.\u001b[39minit_regressors(\u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m ML\u001b[39m.\u001b[39;49mtrain_test_validation()\n",
      "File \u001b[0;32m~/Documents/Projects/Sound-OOP/notebooks/../src/sound_oop.py:119\u001b[0m, in \u001b[0;36mSoundObjectOriented.ml.train_test_validation\u001b[0;34m(self, show_results)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_test_validation\u001b[39m(\u001b[39mself\u001b[39m, show_results\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ML_\u001b[39m.\u001b[39;49mtrain_test_eval_show_results(show\u001b[39m=\u001b[39;49mshow_results)\n",
      "File \u001b[0;32m~/Documents/Projects/Sound-OOP/notebooks/../src/ml.py:154\u001b[0m, in \u001b[0;36mML.train_test_eval_show_results\u001b[0;34m(self, show)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    152\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreg_models:\n\u001b[1;32m    153\u001b[0m     \u001b[39m# fitting the model\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreg_models[name]\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX_train, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_train)\n\u001b[1;32m    156\u001b[0m     \u001b[39m# make predictions with train and test datasets\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     y_pred_train \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/librosa/lib/python3.10/site-packages/sklearn/linear_model/_bayes.py:240\u001b[0m, in \u001b[0;36mBayesianRidge.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    234\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mn_iter should be greater than or equal to 1. Got \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    236\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter\n\u001b[1;32m    237\u001b[0m         )\n\u001b[1;32m    238\u001b[0m     )\n\u001b[0;32m--> 240\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, y, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    242\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/librosa/lib/python3.10/site-packages/sklearn/base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    580\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/librosa/lib/python3.10/site-packages/sklearn/utils/validation.py:979\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    964\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    965\u001b[0m     X,\n\u001b[1;32m    966\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    976\u001b[0m     estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m    977\u001b[0m )\n\u001b[0;32m--> 979\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39;49mmulti_output, y_numeric\u001b[39m=\u001b[39;49my_numeric)\n\u001b[1;32m    981\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m    983\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/miniconda3/envs/librosa/lib/python3.10/site-packages/sklearn/utils/validation.py:993\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[1;32m    989\u001b[0m     y \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    990\u001b[0m         y, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, force_all_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    991\u001b[0m     )\n\u001b[1;32m    992\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 993\u001b[0m     y \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    994\u001b[0m     _assert_all_finite(y)\n\u001b[1;32m    995\u001b[0m     _ensure_no_complex_data(y)\n",
      "File \u001b[0;32m~/miniconda3/envs/librosa/lib/python3.10/site-packages/sklearn/utils/validation.py:1038\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1030\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA column-vector y was passed when a 1d array was\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1031\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m expected. Please change the shape of y to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   1035\u001b[0m         )\n\u001b[1;32m   1036\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mravel(y)\n\u001b[0;32m-> 1038\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1039\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39my should be a 1d array, got an array of shape \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(shape)\n\u001b[1;32m   1040\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (24, 3) instead."
     ]
    }
   ],
   "source": [
    "sound_oop = SoundObjectOriented()\n",
    "sound_oop.add_data(train_extracted, test_extracted, y_train, index_name=\"fname\")\n",
    "# sound_oop.information()\n",
    "sound_oop.pre_processing()\n",
    "# sound_oop.information()\n",
    "\n",
    "ML = sound_oop.ml(sound_oop)\n",
    "ML.show_available_algorithms()\n",
    "ML.init_regressors(\"all\")\n",
    "ML.train_test_validation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "librosa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68990369dbd1e9394bee0e5a26ce0dcb2645a620c500056b6bd9de852964a963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
